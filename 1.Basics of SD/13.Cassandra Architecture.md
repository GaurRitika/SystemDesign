Cassandra is one of the **most important NoSQL databases** to understand for **System Design interviews**, because it embodies **horizontal scalability, high availability, and fault tolerance** ‚Äî all without a single point of failure.
You don't need to learn everything but need to have a surface level knowledge of cassandra as a fresher. Well , deep explanation is given below. Just go throughly‚úåÔ∏è
---

# üß© Phase 1: What Cassandra Is ‚Äî Intuition

> **Apache Cassandra** is a **distributed, NoSQL, column-family database** designed to handle **huge volumes of data** across **many servers**, without downtime.

Think of it like:

* A **Google Bigtable clone** built to be **Amazon DynamoDB-like** (combines both ideas)
* Designed for **real-time analytics** and **high write throughput**

Cassandra trades off some consistency for **availability + partition tolerance (AP)** in the **CAP theorem**.

---

# üåç Phase 2: High-Level Analogy

Imagine you‚Äôre building **Instagram Analytics** ‚Äî
you store data like:

* every post view
* every like
* every comment
* every impression

This is *massive data*, continuously being written.

A single database (like MySQL) would die.
Cassandra solves this by **splitting the data across many nodes**, and each node can take **reads/writes independently**.

---

# ‚öôÔ∏è Phase 3: Core Architecture Components

Let‚Äôs break down Cassandra into its building blocks:

| Component                   | Purpose                                                       |
| --------------------------- | ------------------------------------------------------------- |
| **Cluster**                 | The whole Cassandra installation (group of nodes)             |
| **Node**                    | A single machine (physical or virtual)                        |
| **Data Center**             | A logical grouping of related nodes (like per region)         |
| **Keyspace**                | Like a database in SQL ‚Äî top-level namespace                  |
| **Table (Column Family)**   | Like a table ‚Äî stores rows with columns                       |
| **Row Key / Partition Key** | Decides which node will store the data                        |
| **Commit Log**              | Write-ahead log for durability                                |
| **MemTable**                | In-memory data structure for fast writes                      |
| **SSTable**                 | Sorted string table on disk (immutable)                       |
| **Bloom Filter**            | Fast in-memory structure to check if a key exists in SSTables |

---

# üß† Phase 4: Cassandra‚Äôs Write Path (Step-by-Step)

When you **write data**, Cassandra follows a specific, efficient process:

### Example:

```sql
INSERT INTO user_activity (user_id, post_id, action, timestamp)
VALUES (123, 456, 'like', '2025-10-21T10:00:00');
```

Here‚Äôs what happens internally:

### Step 1Ô∏è‚É£ ‚Äî Client sends write to any node

* That node becomes the **coordinator** for this request.

### Step 2Ô∏è‚É£ ‚Äî Coordinator hashes the **partition key**

* Uses **consistent hashing** on `user_id` to decide which nodes (replicas) should store it.

### Step 3Ô∏è‚É£ ‚Äî Write goes to **Commit Log**

* Immediately written to disk for durability (like a journal).

### Step 4Ô∏è‚É£ ‚Äî Write goes to **MemTable**

* Stored in-memory for fast access.
* Periodically flushed to disk as **SSTable** (Sorted String Table).

### Step 5Ô∏è‚É£ ‚Äî Acknowledgement

* Once the data is safely in the commit log + memtable, Cassandra returns success to the client.

So Cassandra is **very write-optimized** ‚Äî writes never update data in place.

---

# üíæ Phase 5: Read Path (How Cassandra Reads Data)

Suppose you query:

```sql
SELECT * FROM user_activity WHERE user_id = 123;
```

### Step 1Ô∏è‚É£ ‚Äî Coordinator Node

* Any node can receive your query and acts as the **coordinator**.

### Step 2Ô∏è‚É£ ‚Äî Locating Data

* The coordinator uses the **partition key hash** to find which nodes hold replicas for `user_id = 123`.

### Step 3Ô∏è‚É£ ‚Äî Reading Data

Each replica:

* Checks **MemTable** (in-memory)
* Then **Bloom Filter** to see if key exists in SSTables
* Reads data from **SSTables on disk**
* Merges results if found in multiple SSTables

### Step 4Ô∏è‚É£ ‚Äî Consistency Level

Cassandra supports tunable consistency:

* You can decide how many replicas must respond before confirming read/write.

Examples:

| Consistency | Description                |
| ----------- | -------------------------- |
| ONE         | Wait for 1 replica         |
| QUORUM      | Wait for majority replicas |
| ALL         | Wait for all replicas      |

So you can balance **speed vs consistency**.

---

# üß≠ Phase 6: Data Distribution (Consistent Hashing)

Cassandra‚Äôs data distribution is **ring-based**.

Each node is assigned a **token range** representing a portion of the hash ring.

Example (4 nodes):

```
  Node A: 0 ‚Äì 25
  Node B: 26 ‚Äì 50
  Node C: 51 ‚Äì 75
  Node D: 76 ‚Äì 100
```

When data with `user_id = 37` comes:

* Hash(user_id) = 37
* Stored on Node B

Replication factor decides how many copies exist.
If RF = 3, data is also stored on the next 2 nodes (C, D).

---

# üîÑ Phase 7: Replication & Fault Tolerance

Cassandra is **masterless** ‚Äî every node is equal.

| Concept                     | Explanation                                          |
| --------------------------- | ---------------------------------------------------- |
| **Replication Factor (RF)** | Number of nodes storing each piece of data           |
| **Gossip Protocol**         | Nodes exchange heartbeat info to detect failures     |
| **Hinted Handoff**          | Temporarily store writes for down nodes, apply later |
| **Anti-Entropy Repair**     | Synchronizes replicas periodically (Merkle Trees)    |

So even if a node goes down, others have the data.

---

# üåê Phase 8: Data Model Example (Instagram Analytics)

Let‚Äôs say you design a table:

```sql
CREATE TABLE post_likes (
  post_id bigint,
  user_id bigint,
  liked_at timestamp,
  PRIMARY KEY (post_id, user_id)
);
```

How this maps:

| post_id | user_id | liked_at | Stored On |
| ------- | ------- | -------- | --------- |
| 101     | 2001    | 10:00    | Node A    |
| 101     | 2002    | 10:01    | Node A    |
| 102     | 2001    | 10:02    | Node B    |
| 103     | 2001    | 10:05    | Node C    |

`post_id` ‚Üí partition key ‚Üí decides which node handles that post‚Äôs likes.

So all likes for the same post are stored **together**, making reads per post super fast.

---

# üìà Phase 9: Compaction and Tombstones

When MemTables are flushed to disk as SSTables, Cassandra occasionally **compacts** them:

* Merges overlapping SSTables
* Removes deleted data (marked as tombstones)
* Keeps reads fast and disk usage optimized

---

# ‚öñÔ∏è Phase 10: Cassandra in the CAP Theorem

| Property                | Supported? | Notes                  |
| ----------------------- | ---------- | ---------------------- |
| **Consistency**         | Tunable    | QUORUM / ALL           |
| **Availability**        | Yes        | Always serves requests |
| **Partition Tolerance** | Yes        | Designed for it        |

Cassandra focuses on **AP** (Availability + Partition tolerance)
and lets the user tune **Consistency** per query.

---

# üîç Phase 11: Summary Table

| Concept          | Description                                         |
| ---------------- | --------------------------------------------------- |
| **Type**         | Column-Family NoSQL (inspired by BigTable + Dynamo) |
| **Scaling**      | Horizontal (add more nodes easily)                  |
| **Master/Slave** | None ‚Äî all nodes equal                              |
| **Write Path**   | Commit Log ‚Üí MemTable ‚Üí SSTable                     |
| **Read Path**    | MemTable + Bloom Filter + SSTables                  |
| **Replication**  | Configurable (per keyspace)                         |
| **Consistency**  | Tunable (ONE, QUORUM, ALL)                          |
| **Use Case**     | High write throughput (analytics, feeds, logs)      |

---

# üìä Phase 12: In Instagram Context

| Component                    | DB        | Reason                  |
| ---------------------------- | --------- | ----------------------- |
| Post likes/comments counters | Cassandra | High write throughput   |
| Feed activity tracking       | Cassandra | Append-only time-series |
| Logging & metrics            | Cassandra | High ingestion volume   |
| User graph                   | Neo4j     | Relationship-heavy      |
| User data                    | Postgres  | Strong consistency      |

---

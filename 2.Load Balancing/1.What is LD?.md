##  What is Load Balancing?

**Load Balancing** is the technique of **distributing incoming network traffic or workload across multiple servers** so that no single server is overwhelmed â€” ensuring **high availability, reliability, and performance**.

---

###  Real-life Analogy

Imagine you own a restaurant chain ï¿½ï¸

* You have 5 branches (servers).
* Customers (users) enter from one main reception desk (load balancer).
* The receptionist decides which branch should handle the next customer â€” based on whoâ€™s least busy.

âž¡ï¸ That receptionist = **Load Balancer**
âž¡ï¸ Branches = **Servers**
âž¡ï¸ Customers = **Client requests**

This ensures all branches work efficiently and no single one gets overloaded.

---

##  Why Load Balancing?

When you have **millions of users (e.g., Instagram, YouTube)**, one server canâ€™t handle all requests.
Without balancing:

* One server may crash under heavy traffic.
* Others may remain idle.

So, **load balancers**:

* Split requests efficiently across servers.
* Keep the system available even if one server fails.

---

##  Types of Load Balancing

There are **two broad types**:

---

### **1. Hardware Load Balancers**

* Physical devices (e.g., F5, Citrix NetScaler)
* Installed in data centers
* Used by large enterprises
* Super fast, but expensive and less flexible

---

### **2. Software Load Balancers**

* Run as programs or services
* Examples: **Nginx**, **HAProxy**, **Envoy**, **AWS Elastic Load Balancer**
* Cheaper, more flexible, easily scalable
* Commonly used in cloud architectures

---

##  Load Balancer Architecture (Simplified)

```
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Clients     â”‚
        â”‚ (Users, Apps) â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  Load Balancer   â”‚
      â”‚ (Decides Target) â”‚
      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â–¼           â–¼            â–¼
Server A   Server B     Server C
```

**Process:**

1. Clients send requests to one IP (load balancer IP).
2. Load balancer chooses a backend server using an **algorithm**.
3. Response is sent back to client transparently.

---

##  Load Balancing Algorithms

Different ways to decide *which server gets the next request* ðŸ‘‡

| Algorithm                          | Description                                                   | Use Case                                  |
| ---------------------------------- | ------------------------------------------------------------- | ----------------------------------------- |
| **Round Robin**                    | Sends each request to the next server in order                | Simple, good when servers are similar     |
| **Weighted Round Robin**           | Some servers get more requests based on power/capacity        | When servers have different specs         |
| **Least Connections**              | Send new request to the server with fewest active connections | Dynamic loads (e.g., DB-heavy apps)       |
| **IP Hash**                        | Clientâ€™s IP decides which server to send to                   | Sticky sessions (same user â†’ same server) |
| **Random**                         | Pick any server randomly                                      | Testing or small scale                    |
| **Response Time / CPU load-based** | Send to server with fastest response or lowest CPU            | Intelligent, adaptive balancing           |

---

##  Example â€” Instagram Feed System

When you open Instagram:

1. Request â†’ `loadbalancer.instagram.com`
2. Load Balancer checks backend health (availability)
3. Applies balancing rule (e.g., least connections)
4. Sends request to `feed-server-3`
5. Server processes and sends feed data â†’ Load balancer â†’ You

If `feed-server-3` crashes, LB automatically reroutes traffic to another server.

---

##  Benefits of Load Balancing

| Benefit               | Explanation                                    |
| --------------------- | ---------------------------------------------- |
| **Scalability**       | Easily add more servers under the balancer     |
| **High Availability** | If one server fails, others handle load        |
| **Fault Tolerance**   | Auto rerouting keeps system up                 |
| **Performance**       | Distributes load evenly â†’ faster responses     |
| **Security**          | LB hides internal servers behind one public IP |

---

##  Load Balancing Strategies (System Design View)

| Layer                      | Type                              | Example                   |
| -------------------------- | --------------------------------- | ------------------------- |
| **DNS Level**              | Uses multiple IPs for a domain    | Cloudflare, AWS Route53   |
| **Transport Level (L4)**   | Uses IP & Port info (no app data) | HAProxy, Nginx (TCP mode) |
| **Application Level (L7)** | Uses HTTP headers, cookies, URLs  | Nginx, Envoy, AWS ALB     |

---

##  Health Checks

Load balancers **periodically ping servers** to see if theyâ€™re alive:

* Ping `/health` or `/status` endpoint
* If no response â†’ temporarily remove server from pool
* Auto-recover when server comes back online

This ensures **fault tolerance** and **zero downtime**.

---

##  Session Persistence (Sticky Sessions)

Sometimes, you want **the same user to always go to the same server**, especially if the session is stored in memory.

Example:

* User logs into Instagram.
* Load balancer routes them to Server B.
* Server B stores session in memory.
* LB ensures same user â†’ same server next time (using IP hash or cookies).

---

##  Example: System Design Diagram (Instagram)

```
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   Users       â”‚
            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Load Balancer     â”‚
        â”‚ (Nginx / AWS ALB)  â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â–¼             â–¼                â–¼
App Server 1  App Server 2    App Server 3
   |             |                |
   â–¼             â–¼                â–¼
Database       Cache            Media Server
```

---

##  Interview-Level Answer:

> **Load Balancing** is the process of distributing incoming traffic or computational load across multiple servers to ensure no single server becomes a bottleneck. It improves performance, availability, and fault tolerance. Load balancers can use algorithms like Round Robin, Least Connections, or IP Hash, and can operate at various layers (L4 or L7).

---

##  Real Systems Using Load Balancing

| Company    | Load Balancer Used          |
| ---------- | --------------------------- |
| Instagram  | Nginx + Envoy               |
| Netflix    | Zuul + AWS ALB              |
| Google     | Maglev (custom LB)          |
| Amazon     | Elastic Load Balancer (ELB) |
| Cloudflare | Global Anycast LB           |

---
